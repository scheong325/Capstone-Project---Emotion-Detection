{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.020682,
     "end_time": "2020-10-08T08:21:31.277478",
     "exception": false,
     "start_time": "2020-10-08T08:21:31.256796",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Facial Emotion Recogination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.018517,
     "end_time": "2020-10-08T08:21:31.315915",
     "exception": false,
     "start_time": "2020-10-08T08:21:31.297398",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2020-10-08T08:21:31.362590Z",
     "iopub.status.busy": "2020-10-08T08:21:31.361789Z",
     "iopub.status.idle": "2020-10-08T08:21:36.655156Z",
     "shell.execute_reply": "2020-10-08T08:21:36.655769Z"
    },
    "papermill": {
     "duration": 5.320742,
     "end_time": "2020-10-08T08:21:36.655995",
     "exception": false,
     "start_time": "2020-10-08T08:21:31.335253",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras_preprocessing.image import ImageDataGenerator, load_img\n",
    "import cv2\n",
    "from keras.layers import Conv2D, Dense, BatchNormalization, Activation, Dropout, MaxPooling2D, Flatten\n",
    "from keras.optimizers import Adam, RMSprop, SGD\n",
    "from keras import regularizers\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.030612,
     "end_time": "2020-10-08T08:21:36.728766",
     "exception": false,
     "start_time": "2020-10-08T08:21:36.698154",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-08T08:21:36.803496Z",
     "iopub.status.busy": "2020-10-08T08:21:36.802537Z",
     "iopub.status.idle": "2020-10-08T08:21:37.272572Z",
     "shell.execute_reply": "2020-10-08T08:21:37.274101Z"
    },
    "papermill": {
     "duration": 0.514189,
     "end_time": "2020-10-08T08:21:37.274335",
     "exception": false,
     "start_time": "2020-10-08T08:21:36.760146",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data_dir = 'C:/Users/Grace/Desktop/Capstone-Project---Emotion-Detection/data/train/'\n",
    "test_data_dir = 'C:/Users/Grace/Desktop/Capstone-Project---Emotion-Detection/data/test/'\n",
    "\n",
    "row, col = 48, 48\n",
    "classes = 7\n",
    "\n",
    "def count_exp(path, set_):\n",
    "    dict_ = {}\n",
    "    for expression in os.listdir(path):\n",
    "        dir_ = path + expression\n",
    "        dict_[expression] = len(os.listdir(dir_))\n",
    "    df = pd.DataFrame(dict_, index=[set_])\n",
    "    return df\n",
    "train_data_count = count_exp(train_data_dir, 'train data')\n",
    "test_data_count = count_exp(test_data_dir, 'test data')\n",
    "print(train_data_count)\n",
    "print(test_data_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.023055,
     "end_time": "2020-10-08T08:21:37.330149",
     "exception": false,
     "start_time": "2020-10-08T08:21:37.307094",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Bar chart for emotion images in train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-08T08:21:37.376264Z",
     "iopub.status.busy": "2020-10-08T08:21:37.375439Z",
     "iopub.status.idle": "2020-10-08T08:21:37.614326Z",
     "shell.execute_reply": "2020-10-08T08:21:37.614889Z"
    },
    "papermill": {
     "duration": 0.264281,
     "end_time": "2020-10-08T08:21:37.615048",
     "exception": false,
     "start_time": "2020-10-08T08:21:37.350767",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data_count.transpose().plot(kind='bar', figsize=(10,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.024904,
     "end_time": "2020-10-08T08:21:37.663929",
     "exception": false,
     "start_time": "2020-10-08T08:21:37.639025",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Bar chart for emotion images in test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-08T08:21:37.732537Z",
     "iopub.status.busy": "2020-10-08T08:21:37.719845Z",
     "iopub.status.idle": "2020-10-08T08:21:37.890761Z",
     "shell.execute_reply": "2020-10-08T08:21:37.891399Z"
    },
    "papermill": {
     "duration": 0.203638,
     "end_time": "2020-10-08T08:21:37.891561",
     "exception": false,
     "start_time": "2020-10-08T08:21:37.687923",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_data_count.transpose().plot(kind='bar', figsize=(10,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples of emotion images in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-08T08:21:37.950459Z",
     "iopub.status.busy": "2020-10-08T08:21:37.949497Z",
     "iopub.status.idle": "2020-10-08T08:21:38.407738Z",
     "shell.execute_reply": "2020-10-08T08:21:38.406799Z"
    },
    "papermill": {
     "duration": 0.490337,
     "end_time": "2020-10-08T08:21:38.407869",
     "exception": false,
     "start_time": "2020-10-08T08:21:37.917532",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,22))\n",
    "i = 1\n",
    "for expression in os.listdir(train_data_dir):\n",
    "    img = load_img((train_data_dir + expression +'/'+ os.listdir(train_data_dir + expression)[1]))\n",
    "    plt.subplot(1,7,i)\n",
    "    plt.imshow(img)\n",
    "    plt.title(expression)\n",
    "    plt.axis('off')\n",
    "    i += 1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.024558,
     "end_time": "2020-10-08T08:21:38.457547",
     "exception": false,
     "start_time": "2020-10-08T08:21:38.432989",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Create Training and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-08T08:21:38.515057Z",
     "iopub.status.busy": "2020-10-08T08:21:38.514279Z",
     "iopub.status.idle": "2020-10-08T08:21:44.499528Z",
     "shell.execute_reply": "2020-10-08T08:21:44.499002Z"
    },
    "papermill": {
     "duration": 6.016879,
     "end_time": "2020-10-08T08:21:44.499643",
     "exception": false,
     "start_time": "2020-10-08T08:21:38.482764",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data_generator = ImageDataGenerator(rescale=1./255,\n",
    "                                   zoom_range=0.3,\n",
    "                                   horizontal_flip=True)\n",
    "\n",
    "training_set = train_data_generator.flow_from_directory(train_data_dir,\n",
    "                                                batch_size=64,\n",
    "                                                target_size=(48,48),\n",
    "                                                shuffle=True,\n",
    "                                                color_mode='grayscale',\n",
    "                                                class_mode='categorical')\n",
    "\n",
    "test_data_generator = ImageDataGenerator(rescale=1./255)\n",
    "test_set = test_data_generator.flow_from_directory(test_data_dir,\n",
    "                                                batch_size=64,\n",
    "                                                target_size=(48,48),\n",
    "                                                shuffle=True,\n",
    "                                                color_mode='grayscale',\n",
    "                                                class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-08T08:21:44.557938Z",
     "iopub.status.busy": "2020-10-08T08:21:44.557063Z",
     "iopub.status.idle": "2020-10-08T08:21:44.561222Z",
     "shell.execute_reply": "2020-10-08T08:21:44.560739Z"
    },
    "papermill": {
     "duration": 0.03518,
     "end_time": "2020-10-08T08:21:44.561327",
     "exception": false,
     "start_time": "2020-10-08T08:21:44.526147",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_set.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.025515,
     "end_time": "2020-10-08T08:21:44.612280",
     "exception": false,
     "start_time": "2020-10-08T08:21:44.586765",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Constructure Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-08T08:21:44.681352Z",
     "iopub.status.busy": "2020-10-08T08:21:44.680378Z",
     "iopub.status.idle": "2020-10-08T08:21:44.683419Z",
     "shell.execute_reply": "2020-10-08T08:21:44.682923Z"
    },
    "papermill": {
     "duration": 0.045419,
     "end_time": "2020-10-08T08:21:44.683519",
     "exception": false,
     "start_time": "2020-10-08T08:21:44.638100",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Sequential()   \n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), padding='same', activation='relu', input_shape=(48,48,1)))\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(2, 2))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Conv2D(256, kernel_size=(3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "    \n",
    "model.add(Dense(classes, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer=Adam(lr=0.0001, decay=1e-6), \n",
    "                loss='categorical_crossentropy', \n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.029194,
     "end_time": "2020-10-08T08:21:48.768485",
     "exception": false,
     "start_time": "2020-10-08T08:21:48.739291",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-08T08:21:48.836175Z",
     "iopub.status.busy": "2020-10-08T08:21:48.835472Z",
     "iopub.status.idle": "2020-10-08T09:03:29.511581Z",
     "shell.execute_reply": "2020-10-08T09:03:29.510961Z"
    },
    "papermill": {
     "duration": 2500.711354,
     "end_time": "2020-10-08T09:03:29.511710",
     "exception": false,
     "start_time": "2020-10-08T08:21:48.800356",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "steps_per_epoch = training_set.n // training_set.batch_size\n",
    "validation_steps = test_set.n // test_set.batch_size\n",
    "hist = model.fit(x=training_set,\n",
    "                 validation_data=test_set,\n",
    "                 epochs=60,\n",
    "                 steps_per_epoch=steps_per_epoch,\n",
    "                 validation_steps=validation_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 10.924119,
     "end_time": "2020-10-08T09:03:51.155021",
     "exception": false,
     "start_time": "2020-10-08T09:03:40.230902",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Loss and Accuracy plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-08T09:04:13.368739Z",
     "iopub.status.busy": "2020-10-08T09:04:13.360682Z",
     "iopub.status.idle": "2020-10-08T09:04:13.705368Z",
     "shell.execute_reply": "2020-10-08T09:04:13.705946Z"
    },
    "papermill": {
     "duration": 11.065454,
     "end_time": "2020-10-08T09:04:13.706115",
     "exception": false,
     "start_time": "2020-10-08T09:04:02.640661",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,5))\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(hist.history['accuracy'])\n",
    "plt.plot(hist.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title('model Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 10.631613,
     "end_time": "2020-10-08T09:04:35.200516",
     "exception": false,
     "start_time": "2020-10-08T09:04:24.568903",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "high accracy is achieved on training set but accuracy on validation set is stuck at 66% also no overfitting can se seen in the dataset hence is can be concluded that the inefficiency may be due to the unbalanced dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 11.092708,
     "end_time": "2020-10-08T09:04:56.961972",
     "exception": false,
     "start_time": "2020-10-08T09:04:45.869264",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-08T09:05:19.256938Z",
     "iopub.status.busy": "2020-10-08T09:05:19.256248Z",
     "iopub.status.idle": "2020-10-08T09:05:54.067354Z",
     "shell.execute_reply": "2020-10-08T09:05:54.066292Z"
    },
    "papermill": {
     "duration": 45.661739,
     "end_time": "2020-10-08T09:05:54.067516",
     "exception": false,
     "start_time": "2020-10-08T09:05:08.405777",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_loss, train_accu = model.evaluate(training_set) #Evaluates train data for accuracy and loss \n",
    "test_loss, test_accu = model.evaluate(test_set) #Evaluates test data for accuracy and loss \n",
    "print(\"final train accuracy = {:.2f} , validation accuracy = {:.2f}\".format(train_accu*100, test_accu*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Serialize the model to JSON and save the model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-08T09:06:17.775174Z",
     "iopub.status.busy": "2020-10-08T09:06:17.774051Z",
     "iopub.status.idle": "2020-10-08T09:06:18.048124Z",
     "shell.execute_reply": "2020-10-08T09:06:18.047464Z"
    },
    "papermill": {
     "duration": 11.722198,
     "end_time": "2020-10-08T09:06:18.048261",
     "exception": false,
     "start_time": "2020-10-08T09:06:06.326063",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save_weights(\"model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import model weight and haar cascade file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "from PIL import Image\n",
    "model = model_from_json(open(\"model.json\", \"r\").read())\n",
    "model.load_weights('model.h5')\n",
    "face_haar_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct frame to capture the image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap=cv2.VideoCapture(0) # Create an object to read from camera\n",
    "\n",
    "while True:  \n",
    "    ret,frame=cap.read()# Captures frame and returns boolean value  \n",
    "    if not ret:  \n",
    "        continue  \n",
    "    gray_img= cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)  \n",
    "  \n",
    "    faces_detected = face_haar_cascade.detectMultiScale(gray_img, 1.32, 5)  \n",
    "  \n",
    "  \n",
    "    for (x,y,w,h) in faces_detected:  \n",
    "        cv2.rectangle(frame,(x,y),(x+w,y+h),(255,0,0),thickness=7)  \n",
    "        roi_gray=gray_img[y:y+w,x:x+h] # Captures faces \n",
    "        roi_gray=cv2.resize(roi_gray,(48,48))  \n",
    "        img_pixels = tf.keras.utils.img_to_array(roi_gray)  \n",
    "        img_pixels = np.expand_dims(img_pixels, axis = 0)  \n",
    "        img_pixels /= 255  \n",
    "  \n",
    "        predictions = model.predict(img_pixels)  \n",
    "   \n",
    "        max_index = np.argmax(predictions[0])  #Find max indexed array \n",
    "  \n",
    "        emotions = ('angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral')  \n",
    "        predicted_emotion = emotions[max_index]  \n",
    "  \n",
    "        cv2.putText(frame, predicted_emotion, (int(x), int(y)), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)  \n",
    "  \n",
    "    resized_img = cv2.resize(frame, (1000, 700))  \n",
    "    cv2.imshow('Facial emotion analysis ',resized_img)  \n",
    "  \n",
    "  \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'): #Press q to exit process\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows() #Close all the windows"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "papermill": {
   "duration": 2830.346368,
   "end_time": "2020-10-08T09:08:37.334816",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-10-08T08:21:26.988448",
   "version": "2.1.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "84ebcf86d8cf8c8247230adf44b2c3d0a01ce370eb7149dc6cb1724fddab288b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
